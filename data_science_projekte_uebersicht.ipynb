{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49502a5",
   "metadata": {},
   "source": [
    "# Data Science Projekte √úbersicht\n",
    "\n",
    "\n",
    "## üìã Inhaltsverzeichnis\n",
    "\n",
    "1. [Technologie Stack & Tools](#technologie-stack--tools)\n",
    "2. [In-Play Modellierung - Gewinnwahrscheinlichkeiten](#in-play-modellierung---gewinnwahrscheinlichkeiten-zeitreihe)\n",
    "3. [Trading Data Anomalie Detection](#trading-data-anomalie-detection-fraud-detection)\n",
    "4. [Transfer auf VELI Hausnotrufsysteme](#transfer-auf-veli-hausnotrufsysteme---anwendung-der-erfahrungen)\n",
    "   - [Echtzeit-Verhaltensmuster-Erkennung](#1-in-play-modellierung--echtzeit-verhaltensmuster-erkennung-in-energiedaten)\n",
    "   - [Notfall-Fr√ºherkennung](#-2-anomalie-detection--notfall-fr√ºherkennung)\n",
    "   - [Technische Implementierung](#-technische-implementierung-bei-veli)\n",
    "5. [Challenges & Herausforderungen](#challenges--herausforderungen-in-der-praxis)\n",
    "\n",
    "---\n",
    "\n",
    "## √úbersicht √ºber aktuelle Data Science Projekte\n",
    "\n",
    "Dieses Notebook bietet eine strukturierte √úbersicht √ºber drei Projekte die ich betreut oder entwickelt habe im Fu√üball Data Science Bereich, welche sich auf verschiedene Aspekte der Datenanalyse und -modellierung konzentrieren und auf die Datendom√§ne von VELI transferieren lassen.\n",
    "\n",
    "1. **In-Play Modellierung** - Zeitreihen-basierte Gewinnwahrscheinlichkeiten\n",
    "2. **Trading Data Anomalie Detection** - Fraud Detection und Anomalieerkennung  \n",
    "3. **High Frequency Trading Models** - Streaming Data Processing\n",
    "\n",
    "---\n",
    "\n",
    "### Technologie Stack / Bereits benutzte Technologien mit denen ich gearbeitet habe / Pr√§ferierte Pakete\n",
    "- **Data Streaming**: Apache Kafka, Spark, FastAPI, Allgemein Rest APIs, erster Erfahrungen mit RabbitMQ\n",
    "- **Data Storage**: Amazon S3, MySQL, PostgreSQL, MongoDB, erfahren mit sql\n",
    "- **Data Processing**: Pandas, NumPy, dplyr Universe, dbt\n",
    "- **Analytics**: Python, R\n",
    "- **Machine Learning**: Scikit-learn, TensorFlow, PyTorch\n",
    "- **Visualization**: Matplotlib, Seaborn, Plotly, ggplot2\n",
    "- **Time Series**: (S)ARIMA, Klassisch ACF, LSTM, Seasonal Decomposition, Trend vs. Saisonalit√§t?\n",
    "\n",
    "\n",
    "### Produkt Ideen f√ºr VELI:\n",
    "- Audio Auswertung - Normale Ger√§usche? Schreie? \n",
    "- Demenzerkennung - Ungew√∂hnliche Muster im Tagesablauf, Ver√§nderte Routinen, Herd oft angelassen?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021c692",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. In-Play Modellierung - Gewinnwahrscheinlichkeiten (Zeitreihe) \n",
    "\n",
    "### Problembeschreibung:\n",
    "Gibt es Ineffizienzen in Live Quote w√§hrend des Spiels?\n",
    "\n",
    "### Projektbeschreibung\n",
    "Entwicklung von Echtzeit-Modellen zur Vorhersage von Gewinnwahrscheinlichkeiten w√§hrend laufender Sportereignisse.\n",
    "\n",
    "Grundlage: Fu√üball Spiel hat 90 Minuten, in denen sich die Gewinnwahrscheinlichkeiten dynamisch √§ndern. Ziel ist es, diese Wahrscheinlichkeiten in Echtzeit zu berechnen und anzupassen. Es gibt 3 Ausg√§nge: Heimsieg, Unentschieden, Ausw√§rtssieg.\n",
    "\n",
    "\n",
    "### Kernkomponenten\n",
    "1. **Datenakquisition**: Live-Sport-Feeds √ºber APIs\n",
    "2. **Feature Engineering**: Zeitreihen-Features, Rolling Statistics, Aktuelle Statistiken vs. Live Stats - z.B. Ballbesitz, Torsch√ºsse, Ecken - Anomalie Detection - Was l√§uft schief?\n",
    "3. **Modellierung**: ARIMA, LSTM, Ensemble Methods, (Hidden) Markov Ketten\n",
    "4. **Deployment**: Real-time Prediction API -> Anomalie? Place Trades\n",
    "\n",
    "### Herausforderungen\n",
    "- Unsaubere Daten: Live-Feeds sind oft unvollst√§ndig oder inkonsistent\n",
    "- Echtzeit-Verarbeitung: Hohe Latenzzeiten bei der Datenverarbeitung\n",
    "- Fu√üballdaten enthalten viel Rauschen und h√§ufige \"State\" Wechsel sind gew√∂hnlich (z.B. Tor, Rote Karte, Verletzung etc.)\n",
    "\n",
    "### Genutzte Modelle\n",
    "- Markov Ketten\n",
    "- ARIMA\n",
    "- Monte Carlo Simulation (f√ºr probabilistische Vorhersagen - Problematisch dass sie lange Laufzeiten haben, da sie auf viele Simulationen angewiesen sind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce0c2a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Trading Data Anomalie Detection (Fraud Detection)\n",
    "### Projektbeschreibung\n",
    "Entwicklung von Machine Learning Algorithmen zur Erkennung anomaler Handelsaktivit√§ten und potentieller Betrugsf√§lle in Kooperation mit einem Buchmacher.\n",
    "\n",
    "### Anwendungsbereiche\n",
    "- **Market Manipulation Detection**: Erkennung von Pump & Dump Schemes - z.B. hohe Aktivit√§t vs. ungew√∂hntlich Hohe aktivit√§t\n",
    "- **Unusual Trading Patterns**: Identifikation verd√§chtiger Handelsvolumen\n",
    "- **Account Anomalies**: Abweichende Nutzerverhalten\n",
    "- **Price Anomalies**: Ungew√∂hnliche Preisbewegungen\n",
    "\n",
    "### Methodiken\n",
    "1. **Statistical Methods**: Z-Score, IQR-basierte Outlier Detection\n",
    "2. **Machine Learning**: Isolation Forest, One-Class SVM, Autoencoders\n",
    "3. **Time Series Anomalies**: Change Point Detection, Seasonal Decomposition\n",
    "4. **Graph Analytics**: Netzwerk-basierte Anomalieerkennung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1dadbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Transfer auf VELI Hausnotrufsysteme - Anwendung der Erfahrungen \n",
    "\n",
    "VELI Kontext: Smarte Hausnotrufsysteme aus Energiedaten - √§hnlich wie im Fu√üball wo wir √ºber 200 Variablen pro Spiel haben, haben wir in den Haushaltsdaten sehr viele heterogene Variabelen, die wir in Echtzeit analysieren k√∂nnen. Challenge: Signal vs. Noise - Trennung von Signalen - Was ist der K√ºhlschrank, was ist Herd und was ist das Licht? \n",
    "\n",
    "---\n",
    "\n",
    "## Transfer Fu√üball Projekte auf VELI -> Zeitreihenbasierte Anomalieerkennung \n",
    "\n",
    "###  **1. In-Play Modellierung ‚Üí Echtzeit-Verhaltensmuster-Erkennung in Energiedaten** \n",
    "\n",
    "**√úbertragung:**\n",
    "- **Statt Sportereignisse**: Haushalts-Energieverbrauch √ºber 24h/7 Tage Zyklen -> Dauerhaftes Streaming von Smart Meter Daten\n",
    "- **Statt Gewinnwahrscheinlichkeiten**: Wahrscheinlichkeit f√ºr Notfall/normale Aktivit√§t -> Anomalie Definition wichtig\n",
    "- **Zeitreihen-Features**: T√§gliche Routinen, Wochenmuster, saisonale Schwankungen\n",
    "\n",
    "-> Modelle? Markov Ketten, LSTM, Ensemble Methoden. Wichtig Daten sauber zu haben, gl√§tten, rauschen entfernen.\n",
    "\n",
    "**Konkrete Anwendung:**\n",
    "- **Baseline-Modellierung**: Normale Energiemuster pro Haushalt (K√ºche, Beleuchtung, TV)\n",
    "- **Anomalie-Scores**: Abweichungen von gewohnten Mustern in Echtzeit\n",
    "- **Adaptive Modelle**: Lernen individueller Gewohnheiten (Fr√ºhaufsteher vs. Nachtaktiv)\n",
    "- **Alarm-Trigger**: Gradueller Alarm bei anhaltenden Abweichungen\n",
    "\n",
    "---\n",
    "\n",
    "###  **2. Anomalie Detection ‚Üí Notfall-Fr√ºherkennung**\n",
    "\n",
    "**√úbertragung:**\n",
    "- **Statt Trading-Betrug**: Ungew√∂hnliche Energiemuster als Notfall-Indikatoren\n",
    "- **Statt Market Manipulation**: Pl√∂tzliche Aktivit√§ts-Stopps oder ungew√∂hnliche Spitzen\n",
    "- **Multi-variate Analyse**: Kombination verschiedener Ger√§te-Signaturen\n",
    "\n",
    "**Konkrete Anwendung:**\n",
    "- **Sturz-Erkennung**: Pl√∂tzlicher Stopp aller Aktivit√§ten nach normalem Muster\n",
    "- **Medizinische Notf√§lle**: Ungew√∂hnlich lange Inaktivit√§t oder n√§chtliche Aktivit√§t\n",
    "- **Verhaltens√§nderungen**: Graduelle Verschiebung der Routinen (Krankheit, Depression)\n",
    "- **False-Positive Minimierung**: Unterscheidung Urlaub vs. Notfall durch Muster-Analyse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Weitere (Fu√üball bezogene Projekte):\n",
    "- Scouting Matching Algorithmus\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### üîß **Technische Implementierung bei VELI** \n",
    "\n",
    "**Data Pipeline:**\n",
    "```\n",
    "Smart Meter ‚Üí Kafka Streams ‚Üí Feature Engineering ‚Üí ML Models ‚Üí Alert System\n",
    "     ‚Üì\n",
    "   S3 Data Lake ‚Üê Historical Patterns ‚Üê User Behavior Learning\n",
    "```\n",
    "\n",
    "**Machine Learning Architektur:**\n",
    "- **Personalisierte Modelle**: Ein Modell pro Haushalt f√ºr individuelle Muster\n",
    "- **Ensemble Approach**: Kombination verschiedener Anomalie-Detection Methoden\n",
    "- **Online Learning**: Kontinuierliche Anpassung an sich √§ndernde Gewohnheiten\n",
    "- **Explainable AI**: Nachvollziehbare Begr√ºndung f√ºr Alarme\n",
    "\n",
    "**Skalierbarkeit:**\n",
    "- **Multi-Tenant Architecture**: Tausende Haushalte parallel √ºberwachen\n",
    "- **Edge Computing**: Lokale Vorverarbeitung f√ºr Datenschutz\n",
    "- **Cloud Integration**: Zentrale Modell-Updates und √úberwachung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a187014f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Engineering f√ºr Anomalieerkennung in Energiedaten\n",
    "\n",
    "### √úbersicht\n",
    "Feature Engineering ist ein kritischer Baustein f√ºr erfolgreiche Anomalieerkennung in Smart Home Energiedaten. Die richtige Auswahl und Konstruktion von Features entscheidet ma√ügeblich √ºber die Qualit√§t der Anomalieerkennung und die Minimierung von False Positives.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Zeitbasierte Features\n",
    "- **Stunde des Tages / Wochentag** (zur Erkennung typischer Nutzungsrhythmen)\n",
    "- **Feiertags-Flag** (abweichendes Verhalten m√∂glich)\n",
    "- **Tageszeit-Kategorie** (Morgen, Mittag, Abend, Nacht)\n",
    "- **Laufende Stunden seit letztem Ereignis** (z. B. letzte Ger√§teaktivit√§t)\n",
    "- **Dauer der aktuellen Aktivit√§tsphase** (z. B. wie lange schon Strom flie√üt)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Aktivit√§ts- und Verbrauchsmuster\n",
    "- **Gesamtverbrauch pro Stunde/Tag**\n",
    "- **Varianz des Verbrauchs pro Zeitintervall**\n",
    "- **Anzahl Ger√§tewechsel pro Stunde** (on/off-Events)\n",
    "- **L√§ngste Inaktivit√§tsphase pro Tag**\n",
    "- **Anzahl aktiver Ger√§te gleichzeitig**\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Ger√§te- und Ereignismerkmale (falls Ger√§tesignaturen erkennbar)\n",
    "- **H√§ufigkeit der Nutzung pro Ger√§t** (z. B. Wasserkocher morgens)\n",
    "- **Durchschnittliche Nutzungsdauer pro Ger√§t**\n",
    "- **Typische Startzeit pro Ger√§t** (Median/Uhrzeit der ersten Nutzung)\n",
    "- **Abweichung von der typischen Nutzungszeit**\n",
    "- **Leistungspeak pro Ger√§t** (Maximalverbrauch)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Anomalie-Indikatoren\n",
    "- **Z-Score des aktuellen Verbrauchs** im Vergleich zur Historie\n",
    "- **Abweichung vom gleitenden Mittelwert** (Moving Average Difference)\n",
    "- **Verbrauch au√üerhalb erwarteter Uhrzeit** (z. B. Nachtaktivit√§t)\n",
    "- **Fehlende Nutzung eines \"Routineger√§ts\"** (z. B. kein Kaffee morgens ‚Üí potenzieller Alarm)\n",
    "- **Pl√∂tzlicher Dauerverbrauch eines Ger√§ts** (z. B. Herd an > 2 Stunden)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Sequenz- und Mustererkennung\n",
    "- **Markov-Ketten-√úberg√§nge** zwischen Ger√§tenutzungen\n",
    "- **Tagesprofil-Vergleich** (Cosine Similarity zu Vortagen)\n",
    "- **Cluster-Zugeh√∂rigkeit** (Tagesmuster in Clustern wie \"normal\" vs. \"ungew√∂hnlich\")\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Kontext-Features\n",
    "- **Temperatur/Wetter** (Einfluss auf Heizungs- oder K√ºhlger√§te)\n",
    "- **Anwesenheitsindikatoren** (z. B. wenn alle Ger√§te √ºber Stunden aus sind ‚Üí evtl. abwesend)\n",
    "\n",
    "### üí° **Praktische Implementierung**\n",
    "```python\n",
    "# Beispiel: Zeitbasierte Features\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6])\n",
    "df['time_category'] = pd.cut(df['hour'], bins=[0, 6, 12, 18, 24], \n",
    "                            labels=['Nacht', 'Morgen', 'Mittag', 'Abend'])\n",
    "\n",
    "# Beispiel: Rolling Statistics f√ºr Anomalieerkennung\n",
    "df['consumption_rolling_mean'] = df['consumption'].rolling(window=24).mean()\n",
    "df['consumption_zscore'] = (df['consumption'] - df['consumption_rolling_mean']) / df['consumption'].rolling(window=24).std()\n",
    "```\n",
    "\n",
    "### üéØ **Feature Selection Strategien**\n",
    "- **Korrelationsanalyse**: Entfernung hochkorrelierter Features\n",
    "- **Feature Importance**: Verwendung von Tree-based Models f√ºr Ranking\n",
    "- **Domain Knowledge**: Einbeziehung von Expertenwissen √ºber Haushaltsger√§te\n",
    "- **Dimensionalit√§tsreduktion**: PCA f√ºr hochdimensionale Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd955caa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenges & Herausforderungen in der Praxis\n",
    "\n",
    "### **Labelling**\n",
    "\n",
    "- **Labeling von Anomalien**: Schwierigkeit, echte Notf√§lle von normalen Abweichungen zu unterscheiden\n",
    "- Automatisierte Labeling-Strategien: Nutzung von Expertenwissen, historische Daten und Nutzer-Feedback \n",
    "- Manuelle Validierung: Kostspielig \n",
    "\n",
    "###  **Datenqualit√§t & Preprocessing**\n",
    "- **Schlechte Datenqualit√§t**: Missing Values, inkonsistente Zeitstempel, Sensor-Ausf√§lle\n",
    "- **Rauschen in Energiedaten**: Elektrische Interferenzen, Messungenauigkeiten\n",
    "- **Heterogene Datenquellen**: Verschiedene Smart Meter Typen, unterschiedliche Sampling-Raten\n",
    "- **Datenvolumen**: Terabytes an kontinuierlichen Zeitreihendaten pro Tag\n",
    "- **Datenschutz (DSGVO)**: Anonymisierung vs. Personalisierung Balance\n",
    "\n",
    "###  **Technische Infrastruktur**\n",
    "- **Latenz-Anforderungen**: Sub-Sekunden Reaktionszeiten f√ºr Notf√§lle\n",
    "- **Skalierbarkeit**: Tausende Haushalte gleichzeitig √ºberwachen\n",
    "- **Ausfallsicherheit**: 99.99% Verf√ºgbarkeit f√ºr kritische Systeme\n",
    "- **Edge vs. Cloud**: Lokale Verarbeitung vs. zentrale Intelligenz\n",
    "- **Bandbreiten-Limitierungen**: L√§ndliche Gebiete mit schlechter Internetverbindung\n",
    "\n",
    "### **Machine Learning Herausforderungen**\n",
    "- **Concept Drift**: Sich √§ndernde Gewohnheiten √ºber Zeit (Jahreszeiten, Alter, Gesundheit) - Saisonalit√§t vs. Trends?\n",
    "- **Class Imbalance**: Sehr wenige echte Notf√§lle vs. normale Aktivit√§t -> Wie im Fu√üball (wenige Draws, viele Heimsiege) -> M√∂glichkeiten: SMOTE (Synthetic Minority Over-sampling Technique), XGBoost ist robust\n",
    "- **False Positive Rate**: Balance zwischen Sicherheit und Fehlalarmen -> Richtige Evalueriungsmethoden w√§hlen - PR-AUC Precision Recall Kurve, F1?\n",
    "- **Explainable AI**: Nachvollziehbare Begr√ºndung f√ºr Alarme (Regulatorik)\n",
    "\n",
    "###  **Nutzer & Dom√§nen-spezifisch**\n",
    "- **Individuelle Unterschiede**: Jeder Haushalt hat einzigartige Muster\n",
    "- **Generationsspezifik**: √Ñltere Menschen vs. Tech-affine Nutzer\n",
    "- **Saisonale Variationen**: Heizung im Winter, Klimaanlage im Sommer\n",
    "- **Lebensumst√§nde**: Single-Haushalt vs. Mehrgenerationen-Familie\n",
    "- **Akzeptanz**: Privatsph√§re-Bedenken vs. Sicherheitsbed√ºrfnis\n",
    "\n",
    "###  **Operationelle Herausforderungen**\n",
    "- **Kontinuierliches Monitoring**: 24/7 System√ºberwachung\n",
    "- **Model Maintenance**: Regelm√§√üige Updates und Retraining - Engineering Department?\n",
    "- **Incident Response**: Schnelle Reaktion bei System-Ausf√§llen - Wie ist das bisher geregelt? Gibts da SLA Vereinbarungen mit den Nutzern? Rechtliche Absicherung?\n",
    "- **Quality Assurance**: Testing von ML-Modellen in produktiver Umgebung -> DevOps optimieren.\n",
    "- **Compliance**: Medizintechnik-Regulierung und Zertifizierungen\n",
    "\n",
    "###  **L√∂sungsans√§tze **\n",
    "- **Robuste Preprocessing-Pipelines**: Automated Data Cleaning und Validation -> dbt nutzen\n",
    "- **Ensemble Methods**: Mehrere Modelle f√ºr erh√∂hte Zuverl√§ssigkeit\n",
    "- **Graduelle Alarmierung**: Soft Alerts ‚Üí Family ‚Üí Emergency Services\n",
    "- **Continuous Learning**\n",
    "- **A/B Testing**: Kontinuierliche Optimierung der Algorithmen\n",
    "\n",
    "### **Anlern-Methoden f√ºr neue Standorte**\n",
    "\n",
    "#### **Datensammlung und Baseline-Erstellung**\n",
    "- **Shadow-Mode**: Modell l√§uft ohne Alarme, sammelt 7‚Äì14 Tage Basisdaten\n",
    "- **Active Learning**: Nur unsichere/auff√§llige Events zur Best√§tigung an Pflegepersonal schicken (kleines, fokussiertes Label-Set)\n",
    "- **Few-shot-Kalibrierung**: 5‚Äì10 Beispiele je Schl√ºsselger√§t (K√ºhlschrank, Wasserkocher, Mikrowelle) reichen oft, um Schwellen lokal zu justieren\n",
    "\n",
    "#### **Regel-/Schwellwert-Kalibrierung**\n",
    "- **ROC/PR aus wenigen gelabelten Tagen** ‚Üí standortspezifische Schwellen: Ziel-FPR (False Positive Rate) und Recall nach Risiko priorisieren (z. B. FN teurer als FP)\n",
    "- **Ensemble-Alarm**: Notfall erst, wenn ‚â•2 unabh√§ngige Signale gleichzeitig abweichen (z. B. Strom-Muster + fehlende Routine + Bewegungssensor)\n",
    "\n",
    "#### **Skalierbare Deployment-Strategie**\n",
    "- **Basic Model First**: Zuerst ein skaliertes Grundmodell mit solider Precision/Recall installieren\n",
    "- **Standort-spezifisches Fine-Tuning**: Anschlie√üend Machine Learning Model explizit auf den Standort anpassen\n",
    "- **Iterative Verbesserung**: Kontinuierliche Optimierung basierend auf Feedback und neuen Daten\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
